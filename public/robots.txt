# Robots.txt for GH-CMX Blog
# Controls search engine crawler behavior

# Allow all crawlers
User-agent: *
Allow: /
Disallow: /dashboard
Disallow: /auth
Disallow: /api
Disallow: /.next
Disallow: /node_modules

# Specific crawler rules
User-agent: Googlebot
Allow: /

User-agent: Bingbot
Allow: /

User-agent: Slurp
Allow: /

# Sitemap location
Sitemap: https://yourdomain.com/api/sitemap.xml

# Crawl delay (requests per second)
Crawl-delay: 1
